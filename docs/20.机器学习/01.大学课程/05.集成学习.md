---
title: 集成学习
date: 2021-09-21 20:00:00
permalink: /pages/C7Vn8J
categories: 
  - 机器学习
tags: 
  - false
author: 
  name: yangxin
  link: https://github.com/yangxin6/MechineLearning
---



## 集成学习

- <mark>集成学习</mark>（ensemble learning）本身不是一个单独的机器学习算法，而是通过构建并**结合多个机器学习器**来完成学习任务。也就是我们常说的“博采众长”。集成学习可以用于**分类问题集成，回归问题集成，特征选取集成，异常点检测集成**等。对于训练数据集，训练若干个个体学习器，通过一定的结合策略，就可以最终形成一个强学习器，以达到博采众长的目的。

- 也就是说，集成学习有两个主要的问题需要解决:
  1. 如何得到若干个**个体学习器**
  2. 如何选择一种**结合策略**，将这些个体学习器集合成一个强学习器。

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/ada0.3brgjeuz2wk0.png" alt="ada0" style="zoom:50%;" />

- 个体学习器有两种选择：
  - <mark>同质个体学习器</mark>：所有的个体学习器都是一个种类的，如都是决策树个体学习器，或者都是神经网络个体学习器。
  - <mark>异质个体学习器</mark>：所有的个体学习器不全是一个种类的，如对于分类问题，对训练集采用支持向量机个体学习器，逻辑回归个体学习器和朴素贝叶斯个体学习器来学习，再通过某种结合策略来确定最终的分类强学习器。
- 目前来说，**同质**个体学习器的应用**最广泛**。
- **同质**个体学习器按照个体学习器之间是否存在**依赖关系**分为两类：
  - 个体学习器间存在**强依赖**关系，需要串行生成，如**boosting**系列算法个体学习器间**不存在强依赖**关系，个体学习器并行生成，如bagging和随机森林系列算法。
  - 个体学习器间**不存在强依赖**关系，个体学习器并行生成，如bagging和随机森林系列算法。





## Boosting

**Boosting**算法的工作机制是:

- 首先从训练集用初始权重训练出**一个弱学习器1**，根据其**误差率**表现来**更新**训练样本的**权重**，使得之前弱学习器1学习**误差率高的训练样本点的权重变高**，使得这些点在后面的弱学习器2中得到更多的重视。
- 然后基于**调整权重**后的训练集来**训练**弱学习器2
- 如此重复进行，直到弱学习器数达到事先指定的数目T，最终将这T个弱学习器通过集合策略进行整合，得到最终的强学习器。

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/boosting.4zzxk45tbaw0.png" alt="boosting" style="zoom:67%;" />



## Bagging

- **Bagging**的算法原理和boosting不同，它的弱学习器之间**没有依赖关系**，可以**并行**生成。

- bagging的个体弱学习器的**训练集**是通过**随机采样**得到的。

- 通过T次的**随机采样**，我们就可以得到T个采样集对于这T个采样集，我们可以分别**独立**的训练出T个弱学习器

- 再对这T个弱学习器通过**集合策略**来得到最终的强学习器。

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/Bagging.3gsc5scwdv80.png" alt="Bagging" style="zoom:67%;" />



## 结合策略

- **平均法**：对于数值类的回归预测问题，可以采用平均法作为结合策略。
  - **算术平均**：$H(x)=\frac1{T}\sum\limits^T_1h_i(x)$
  - **加权平均**：$H(x)=\sum\limits^T_1w_ih_i(x) \ w_i \geq 0,\sum\limits^T_1w_i=1$  其中 $w_i$ 是个体学习器 $h_i$ 的权重
- **投票法**：对于**分类**问题的预测，可以使用投票法。
  - **相对多数**投票法：少数服从多数
  - **绝对多数**投票法：得票过半数
  - **加权**投票法：分类票数乘以一个权重系数，对加权票数求和。

- **学习法**：不是对弱学习器的结果做简单的逻辑处理，而是再加上一层学习器，将训练集弱学习器的学习结果作为输入，将训练集的输出作为输出，重新训练一个学习器来得到最终结果。在这种情况下，我们将弱学习器称为初级学习器，将用于结合的学习器称为次级学习器。对于测试集，我们首先用初级学习器预测一次，得到次级学习器的输入样本，再用次级学习器预测一次，得到最终的预测结果。
