---
title: k邻近算法
date: 2021-09-07 22:00:00
permalink: /pages/DAt3JJ
categories: 
  - 机器学习
tags: 
  - kNN
author: 
  name: yangxin
  link: https://github.com/yangxin6/MechineLearning/tree/master/lesson2
---

# 概念

KNN（k Near Neighbor）: k个最近的邻居，即每个样本都可以用它最近的k个邻居来代表。

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/knn0.35l4lhif67g0.png" alt="knn0" style="zoom:75%;" />

k近邻算法是一种**基本分类和回归方法**。本篇文章只讨论分类问题的k近邻法。

**算法思想**：一个样本与数据集中的 k 个样本最详细，如果这 k 个样本中的大多数属于某一个类别，则该样本也属于这个类别。

# 距离

**2个样本的相似性采用<mark>距离</mark>进行度量。**

$L_p$距离定义：

$L_(x_i,x_j)=(\sum \limits_{l=1}^n|x_i^{(l)} - x_j^{(l)}|^p)^{\frac{1}{p}}$

其中， $x_i \in R^n, x_j\in R^n$， $L_\infty(x_i,x_j) = \max \limits_l |x_i^{(l)} - x_j^{(l)}|$

![l](https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/l.5cc3pvitezg0.png)

# 流程

- 计算已知类别数据集中的点与当前点之间的距离
- 按距离递增次序排序
- 选取与当前点距离最小的 k 个点
- 统计前 k 个点坐在的类别出现的频率
- 返回前 k 个点出现频率最高的类别作为当前点的预测分类



# 实例



## 电影分类预测

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/kn1.45icqojxf9k0.png" alt="kn1" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/yangxin6/img-hosting@master/images/kn2.56tp51bb7kk0.png" alt="kn2" style="zoom:50%;" />

```python
import numpy as np
import pandas as pd

df = pd.read_csv('movie.csv', index_col='序号')
movies = df.values # np格式
print('电影如下：')
print(movies)
old = movies[:-1, 1:4]
new = movies[-1, 1:4]
name = movies[-1, 0]
# 距离计算
L = np.sqrt(np.array([np.sum(np.square(old - new), axis=1)],dtype=float).T)
# 最相似的电影
K = 5
top = np.argsort(L[:,0])[0:K]
print('---------------------------')s
print('与', name, '最相近的5个电影：')
print(np.column_stack((movies[top], np.round(L[top]))))
result = {}
for i in movies[top][:, -1]:
    if i not in result:
        result[i] = 1
    else:
        result[i] += 1
print('**********************')
print('其中与', name, '最相近的类型为', max(result,key=result.get))
```

[代码](https://github.com/yangxin6/MechineLearning/blob/master/lesson2/kNN.py)

## kd Tree

详情见[博客](https://yangxin6.github.io/blog/pages/79I6kK/#radius-search%E6%90%9C%E7%B4%A2)

